# ETL - Projet Prefect

Ce projet contient un pipeline ETL qui synchronise les donnÃ©es entre une base SQL Server (On promise) et PostgreSQL (hÃ©berjement AWS) en utilisant Prefect pour l'orchestration.

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- SQL Server
- AWS acces Key / Postgres Acces
- Prefect 3.x

## ğŸš€ Installation

### 1. Cloner le projet

```bash
git clone <your-repo-url>
cd etl_sqlserver_aws
```

### 2. CrÃ©er un environnement virtuel

```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r ../requirements.txt
```

## âš™ï¸ Configuration

### 1. Configuration des bases de donnÃ©es

Modifiez les paramÃ¨tres de connexion dans :

- `etl_sqlserver_aws/database/sqlserver/get_triggers.py` - Configuration SQL Server
- `etl_sqlserver_aws/database/postgres/pg_connect.py` - Configuration PostgreSQL

### 2. Configuration Prefect

Le projet utilise les fichiers de configuration suivants :

- `etl_sqlserver_aws/prefect.yaml` - Configuration principale du projet
- `etl_sqlserver_aws/deployment.yaml` - Configuration du dÃ©ploiement

## ğŸƒâ€â™‚ï¸ ExÃ©cution

### ExecutÃ© un prefect serveur tomporaire (pour un prefect test)

```bash
python main.py
```

### DÃ©ploiement avec Prefect

#### a) Initialier un fichie prefect pour la configuration de votre deployment

```bash
prefect init # Va crÃ©er un fichie de configuration "prefect.yaml"
```

**Ensuite, modifiez le fichier `prefect.yaml` avec les paramÃ¨tres suivants :**

```yaml
# Welcome to your prefect.yaml file! You can use this file for storing and managing
# configuration for deploying your flows. We recommend committing this file to source
# control along with your flow code.

# Generic metadata about this project
name: etl_sqlserver_aws
prefect-version: 3.4.10

# build section allows you to manage and build docker images
build: null

# push section allows you to manage if and how this project is uploaded to remote locations
push: null

# pull section allows you to provide instructions for cloning this project in remote locations
pull:
  - prefect.deployments.steps.set_working_directory:
      directory: PATH\TO\..\etl_sqlserver_aws

# the deployments section allows you to provide configuration for deploying flows
deployments: # can runs manually, via schedule, API, Throught an automation
  - name: sorecom-deployment
    version: null
    tags: []
    description: "DÃ©ploiement rÃ©gulier du pipeline SORECOM"
    schedule:
      cron: "*/10 * * * *"
    flow_name: sorecom_pipeline
    entrypoint: main.py:sorecom_pipeline
    parameters: {}
    work_pool:
      name: default-agent-pool
      work_queue_name: default
      job_variables: {}

  - name: cleanup-triggers-monthly
    version: null
    tags: ["maintenance", "monthly"]
    description: "Nettoyage mensuel des tables de triggers (garde 20 dernieres lignes)"
    schedule:
      cron: "0 0 1 * *" # Chaque 1er du mois Ã  00:00
      timezone: "Etc/UTC"
    flow_name: cleanup_triggers_flow
    entrypoint: main.py:cleanup_triggers_flow
    parameters: {}
    work_pool:
      name: default-agent-pool
      work_queue_name: default
      job_variables: {}
```

### b) DÃ©marrer le serveur Prefect

```bash
prefect server start
```

#### c) DÃ©ployer le flow

```bash
prefect deploy --name sorecom-deployment
```

#### d) DÃ©marrer un worker

```bash
export PREFECT_API_URL="http://127.0.0.1:4200/api"
```

```bash
prefect worker start --pool default-agent-pool
```

## ğŸ“Š Monitoring

- Interface Prefect : `http://localhost:4200`
- Le pipeline s'exÃ©cute toutes les 5 minutes selon la configuration cron `*/5 * * * *`

## ğŸ—‚ï¸ Structure du projet

```
etl_sqlserver_aws/
|-- __ini__.py
â”œâ”€â”€ main.py              # Flow principal
â”œâ”€â”€ deploy.py            # Script de dÃ©ploiement
â”œâ”€â”€ prefect.yaml         # Configuration Prefect
â”œâ”€â”€ deployment.yaml      # Configuration dÃ©ploiement
â””â”€â”€ database/
    â”œâ”€â”€ sqlserver/       # Connexion et requÃªtes SQL Server
    |   |-- __init__.py
    â”‚   â””â”€â”€ get_triggers.py
    â””â”€â”€ postgres/        # Connexion et opÃ©rations PostgreSQL
        |-- __init__.py
        â”œâ”€â”€ pg_connect.py
        â”œâ”€â”€ upload_article.py
        â”œâ”€â”€ upload_famille.py
        â””â”€â”€ upload_stk_reel.py
```

## ğŸ”„ Fonctionnement

Le pipeline `sorecom_pipeline` :

1. **DÃ©tecte les changements** rÃ©cents (5 derniÃ¨res minutes) via les tables trigger
2. **Traite les familles** : CrÃ©ation/modification/suppression des catÃ©gories
3. **Traite les articles** : Synchronisation des produits
4. **Met Ã  jour les stocks** : Actualisation des quantitÃ©s disponibles

## ğŸ› ï¸ Commandes utiles

```bash
# Voir les dÃ©ploiements
prefect deployment ls

# Voir les flows
prefect flow ls

# Voir les runs
prefect flow-run ls

# Supprimer un dÃ©ploiement
prefect deployment delete <deployment-name>

# Logs en temps rÃ©el
prefect flow-run logs --tail <run-id>
```

## ğŸ› DÃ©pannage

1. **Erreur de connexion SQL Server** : VÃ©rifiez les paramÃ¨tres dans `get_triggers.py`
2. **Erreur de connexion PostgreSQL** : VÃ©rifiez les paramÃ¨tres dans `pg_connect.py`
3. **Worker non dÃ©marrÃ©** : Assurez-vous qu'un worker est actif avec `prefect worker start`

## ğŸ“ Notes

- Les fichiers sensibles (`encrypt.py`, `deploy.py`) sont exclus du Git via `.gitignore`
- Le pipeline filtre automatiquement les donnÃ©es des 5 derniÃ¨res minutes
- Les logs sont disponibles dans l'interface Prefect pour le monitoring

## ğŸ”’ SÃ©curitÃ©

- Les informations de connexion aux bases de donnÃ©es doivent Ãªtre configurÃ©es de maniÃ¨re sÃ©curisÃ©e
- Utilisez des variables d'environnement pour les mots de passe et clÃ©s sensibles
- Les fichiers de configuration contenant des credentials sont exclus du contrÃ´le de version
